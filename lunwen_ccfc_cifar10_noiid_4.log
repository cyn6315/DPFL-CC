nohup: ignoring input
cuda:2
Namespace(batch_size=1500, classes_per_user=4, data_root='./datasets', exp_dir='./save/CCFC/cifar10-noiid', global_lr=1, image_size=224, k=10, latent_dim=256, lbd=0.1, lr=0.0005, mini_bs=125, n_clients=40, num_proj_layers=2, num_workers=6, p=0.0, pre_hidden_dim=64, proj_hidden_dim=512, resnet='ResNet18', sample_ratio=0.9, seed=66, test_image_size=256, trial='v0')
save/CCFC/v4/model_pretrain_0_19.pt
Global  NMI = 0.4257 ARI = 0.3172 F = 0.3976 ACC = 0.5486
backbone.conv1.weight 9408 torch.Size([64, 3, 7, 7])
backbone.bn1.weight 64 torch.Size([64])
backbone.bn1.bias 64 torch.Size([64])
backbone.layer1.0.conv1.weight 36864 torch.Size([64, 64, 3, 3])
backbone.layer1.0.bn1.weight 64 torch.Size([64])
backbone.layer1.0.bn1.bias 64 torch.Size([64])
backbone.layer1.0.conv2.weight 36864 torch.Size([64, 64, 3, 3])
backbone.layer1.0.bn2.weight 64 torch.Size([64])
backbone.layer1.0.bn2.bias 64 torch.Size([64])
backbone.layer1.1.conv1.weight 36864 torch.Size([64, 64, 3, 3])
backbone.layer1.1.bn1.weight 64 torch.Size([64])
backbone.layer1.1.bn1.bias 64 torch.Size([64])
backbone.layer1.1.conv2.weight 36864 torch.Size([64, 64, 3, 3])
backbone.layer1.1.bn2.weight 64 torch.Size([64])
backbone.layer1.1.bn2.bias 64 torch.Size([64])
backbone.layer2.0.conv1.weight 73728 torch.Size([128, 64, 3, 3])
backbone.layer2.0.bn1.weight 128 torch.Size([128])
backbone.layer2.0.bn1.bias 128 torch.Size([128])
backbone.layer2.0.conv2.weight 147456 torch.Size([128, 128, 3, 3])
backbone.layer2.0.bn2.weight 128 torch.Size([128])
backbone.layer2.0.bn2.bias 128 torch.Size([128])
backbone.layer2.0.downsample.0.weight 8192 torch.Size([128, 64, 1, 1])
backbone.layer2.0.downsample.1.weight 128 torch.Size([128])
backbone.layer2.0.downsample.1.bias 128 torch.Size([128])
backbone.layer2.1.conv1.weight 147456 torch.Size([128, 128, 3, 3])
backbone.layer2.1.bn1.weight 128 torch.Size([128])
backbone.layer2.1.bn1.bias 128 torch.Size([128])
backbone.layer2.1.conv2.weight 147456 torch.Size([128, 128, 3, 3])
backbone.layer2.1.bn2.weight 128 torch.Size([128])
backbone.layer2.1.bn2.bias 128 torch.Size([128])
backbone.layer3.0.conv1.weight 294912 torch.Size([256, 128, 3, 3])
backbone.layer3.0.bn1.weight 256 torch.Size([256])
backbone.layer3.0.bn1.bias 256 torch.Size([256])
backbone.layer3.0.conv2.weight 589824 torch.Size([256, 256, 3, 3])
backbone.layer3.0.bn2.weight 256 torch.Size([256])
backbone.layer3.0.bn2.bias 256 torch.Size([256])
backbone.layer3.0.downsample.0.weight 32768 torch.Size([256, 128, 1, 1])
backbone.layer3.0.downsample.1.weight 256 torch.Size([256])
backbone.layer3.0.downsample.1.bias 256 torch.Size([256])
backbone.layer3.1.conv1.weight 589824 torch.Size([256, 256, 3, 3])
backbone.layer3.1.bn1.weight 256 torch.Size([256])
backbone.layer3.1.bn1.bias 256 torch.Size([256])
backbone.layer3.1.conv2.weight 589824 torch.Size([256, 256, 3, 3])
backbone.layer3.1.bn2.weight 256 torch.Size([256])
backbone.layer3.1.bn2.bias 256 torch.Size([256])
backbone.layer4.0.conv1.weight 1179648 torch.Size([512, 256, 3, 3])
backbone.layer4.0.bn1.weight 512 torch.Size([512])
backbone.layer4.0.bn1.bias 512 torch.Size([512])
backbone.layer4.0.conv2.weight 2359296 torch.Size([512, 512, 3, 3])
backbone.layer4.0.bn2.weight 512 torch.Size([512])
backbone.layer4.0.bn2.bias 512 torch.Size([512])
backbone.layer4.0.downsample.0.weight 131072 torch.Size([512, 256, 1, 1])
backbone.layer4.0.downsample.1.weight 512 torch.Size([512])
backbone.layer4.0.downsample.1.bias 512 torch.Size([512])
backbone.layer4.1.conv1.weight 2359296 torch.Size([512, 512, 3, 3])
backbone.layer4.1.bn1.weight 512 torch.Size([512])
backbone.layer4.1.bn1.bias 512 torch.Size([512])
backbone.layer4.1.conv2.weight 2359296 torch.Size([512, 512, 3, 3])
backbone.layer4.1.bn2.weight 512 torch.Size([512])
backbone.layer4.1.bn2.bias 512 torch.Size([512])
projector.layer1.0.weight 262144 torch.Size([512, 512])
projector.layer1.0.bias 512 torch.Size([512])
projector.layer1.1.weight 512 torch.Size([512])
projector.layer1.1.bias 512 torch.Size([512])
projector.layer2.0.weight 262144 torch.Size([512, 512])
projector.layer2.0.bias 512 torch.Size([512])
projector.layer2.1.weight 512 torch.Size([512])
projector.layer2.1.bias 512 torch.Size([512])
projector.layer3.0.weight 131072 torch.Size([256, 512])
projector.layer3.0.bias 256 torch.Size([256])
predictor.layer1.0.weight 16384 torch.Size([64, 256])
predictor.layer1.0.bias 64 torch.Size([64])
predictor.layer1.1.weight 64 torch.Size([64])
predictor.layer1.1.bias 64 torch.Size([64])
predictor.layer2.weight 16384 torch.Size([256, 64])
predictor.layer2.bias 256 torch.Size([256])
count 36
Round:  0 Train Loss: -1.892
count 36
Round:  1 Train Loss: -1.895
count 36
Round:  2 Train Loss: -1.903
count 36
Round:  3 Train Loss: -1.900
count 36
Round:  4 Train Loss: -1.901
centeral clustering
Global  NMI = 0.3238 ARI = 0.2088 F = 0.2946 ACC = 0.4155
count 36
Round:  5 Train Loss: -1.902
count 36
Round:  6 Train Loss: -1.902
count 36
Round:  7 Train Loss: -1.907
count 36
Round:  8 Train Loss: -1.909
count 36
Round:  9 Train Loss: -1.907
centeral clustering
Global  NMI = 0.3181 ARI = 0.2006 F = 0.2877 ACC = 0.4082
Global  NMI = 0.3806 ARI = 0.2619 F = 0.3570 ACC = 0.4806
count 36
Round:  10 Train Loss: -1.908
count 36
Round:  11 Train Loss: -1.915
count 36
Round:  12 Train Loss: -1.906
count 36
Round:  13 Train Loss: -1.909
count 36
Round:  14 Train Loss: -1.909
centeral clustering
Global  NMI = 0.3119 ARI = 0.1941 F = 0.2820 ACC = 0.4011
count 36
Round:  15 Train Loss: -1.916
count 36
Round:  16 Train Loss: -1.908
count 36
Round:  17 Train Loss: -1.913
count 36
Round:  18 Train Loss: -1.913
count 36
Round:  19 Train Loss: -1.914
centeral clustering
Global  NMI = 0.3119 ARI = 0.1918 F = 0.2793 ACC = 0.3984
Global  NMI = 0.3739 ARI = 0.2559 F = 0.3481 ACC = 0.4693
count 36
Round:  20 Train Loss: -1.912
count 36
Round:  21 Train Loss: -1.912
count 36
Round:  22 Train Loss: -1.918
count 36
Round:  23 Train Loss: -1.912
count 36
Round:  24 Train Loss: -1.918
centeral clustering
Global  NMI = 0.3123 ARI = 0.1905 F = 0.2785 ACC = 0.3973
count 36
Round:  25 Train Loss: -1.916
count 36
Round:  26 Train Loss: -1.916
count 36
Round:  27 Train Loss: -1.916
count 36
Round:  28 Train Loss: -1.917
count 36
Round:  29 Train Loss: -1.922
centeral clustering
Global  NMI = 0.3063 ARI = 0.1835 F = 0.2723 ACC = 0.3912
Global  NMI = 0.3652 ARI = 0.2482 F = 0.3412 ACC = 0.4708
count 36
Round:  30 Train Loss: -1.918
count 36
Round:  31 Train Loss: -1.918
count 36
Round:  32 Train Loss: -1.919
count 36
Round:  33 Train Loss: -1.922
count 36
Round:  34 Train Loss: -1.920
centeral clustering
Global  NMI = 0.3057 ARI = 0.1822 F = 0.2708 ACC = 0.3867
count 36
Round:  35 Train Loss: -1.925
count 36
Round:  36 Train Loss: -1.926
count 36
Round:  37 Train Loss: -1.926
count 36
Round:  38 Train Loss: -1.926
count 36
Round:  39 Train Loss: -1.923
centeral clustering
Global  NMI = 0.3076 ARI = 0.1831 F = 0.2719 ACC = 0.3862
Global  NMI = 0.3629 ARI = 0.2489 F = 0.3399 ACC = 0.4708
count 36
Round:  40 Train Loss: -1.926
count 36
Round:  41 Train Loss: -1.923
count 36
Round:  42 Train Loss: -1.921
count 36
Round:  43 Train Loss: -1.923
count 36
Round:  44 Train Loss: -1.923
centeral clustering
Global  NMI = 0.3032 ARI = 0.1781 F = 0.2679 ACC = 0.3790
count 36
Round:  45 Train Loss: -1.925
count 36
Round:  46 Train Loss: -1.925
count 36
Round:  47 Train Loss: -1.926
count 36
Round:  48 Train Loss: -1.926
count 36
Round:  49 Train Loss: -1.925
centeral clustering
Global  NMI = 0.3035 ARI = 0.1794 F = 0.2684 ACC = 0.3826
Global  NMI = 0.3516 ARI = 0.2024 F = 0.3152 ACC = 0.4126
count 36
Round:  50 Train Loss: -1.925
count 36
Round:  51 Train Loss: -1.925
count 36
Round:  52 Train Loss: -1.923
count 36
Round:  53 Train Loss: -1.929
count 36
Round:  54 Train Loss: -1.922
centeral clustering
Global  NMI = 0.3007 ARI = 0.1750 F = 0.2657 ACC = 0.3739
count 36
Round:  55 Train Loss: -1.926
count 36
Round:  56 Train Loss: -1.925
count 36
Round:  57 Train Loss: -1.929
count 36
Round:  58 Train Loss: -1.925
count 36
Round:  59 Train Loss: -1.931
centeral clustering
Global  NMI = 0.2978 ARI = 0.1733 F = 0.2649 ACC = 0.3700
Global  NMI = 0.3514 ARI = 0.2296 F = 0.3256 ACC = 0.4585
count 36
Round:  60 Train Loss: -1.924
count 36
Round:  61 Train Loss: -1.923
count 36
Round:  62 Train Loss: -1.929
count 36
Round:  63 Train Loss: -1.918
count 36
Round:  64 Train Loss: -1.919
centeral clustering
Global  NMI = 0.2931 ARI = 0.1634 F = 0.2594 ACC = 0.3536
count 36
Round:  65 Train Loss: -1.920
count 36
Round:  66 Train Loss: -1.917
count 36
Round:  67 Train Loss: -1.916
count 36
Round:  68 Train Loss: -1.908
count 36
Round:  69 Train Loss: -1.909
centeral clustering
Global  NMI = 0.2885 ARI = 0.1654 F = 0.2612 ACC = 0.3534
Global  NMI = 0.3400 ARI = 0.2008 F = 0.3164 ACC = 0.4197
count 36
Round:  70 Train Loss: -1.905
count 36
Round:  71 Train Loss: -1.908
count 36
Round:  72 Train Loss: -1.909
count 36
Round:  73 Train Loss: -1.912
count 36
Round:  74 Train Loss: -1.915
centeral clustering
Global  NMI = 0.3032 ARI = 0.1789 F = 0.2801 ACC = 0.3770
count 36
Round:  75 Train Loss: -1.919
count 36
Round:  76 Train Loss: -1.912
count 36
Round:  77 Train Loss: -1.915
count 36
Round:  78 Train Loss: -1.923
count 36
Round:  79 Train Loss: -1.927
centeral clustering
Global  NMI = 0.2970 ARI = 0.1733 F = 0.2679 ACC = 0.3512
Global  NMI = 0.3668 ARI = 0.2107 F = 0.3350 ACC = 0.4269
count 36
Round:  80 Train Loss: -1.919
count 36
Round:  81 Train Loss: -1.925
count 36
Round:  82 Train Loss: -1.922
count 36
Round:  83 Train Loss: -1.923
count 36
Round:  84 Train Loss: -1.922
centeral clustering
Global  NMI = 0.2959 ARI = 0.1723 F = 0.2688 ACC = 0.3431
count 36
Round:  85 Train Loss: -1.925
count 36
Round:  86 Train Loss: -1.929
count 36
Round:  87 Train Loss: -1.930
count 36
Round:  88 Train Loss: -1.932
count 36
Round:  89 Train Loss: -1.929
centeral clustering
Global  NMI = 0.2971 ARI = 0.1752 F = 0.2747 ACC = 0.3671
Global  NMI = 0.3260 ARI = 0.2007 F = 0.3126 ACC = 0.3991
count 36
Round:  90 Train Loss: -1.927
count 36
Round:  91 Train Loss: -1.930
count 36
Round:  92 Train Loss: -1.933
count 36
Round:  93 Train Loss: -1.926
count 36
Round:  94 Train Loss: -1.931
centeral clustering
Global  NMI = 0.2981 ARI = 0.1762 F = 0.2748 ACC = 0.3651
count 36
Round:  95 Train Loss: -1.931
count 36
Round:  96 Train Loss: -1.933
count 36
Round:  97 Train Loss: -1.941
count 36
Round:  98 Train Loss: -1.935
count 36
Round:  99 Train Loss: -1.933
centeral clustering
Global  NMI = 0.2942 ARI = 0.1704 F = 0.2707 ACC = 0.3572
Global  NMI = 0.3045 ARI = 0.1969 F = 0.2935 ACC = 0.3718
count 36
Round:  100 Train Loss: -1.941
count 36
Round:  101 Train Loss: -1.937
count 36
Round:  102 Train Loss: -1.937
count 36
Round:  103 Train Loss: -1.937
count 36
Round:  104 Train Loss: -1.935
centeral clustering
Global  NMI = 0.2885 ARI = 0.1639 F = 0.2620 ACC = 0.3285
count 36
Round:  105 Train Loss: -1.937
count 36
Round:  106 Train Loss: -1.935
count 36
Round:  107 Train Loss: -1.941
count 36
Round:  108 Train Loss: -1.943
count 36
Round:  109 Train Loss: -1.936
centeral clustering
Global  NMI = 0.2885 ARI = 0.1626 F = 0.2606 ACC = 0.3246
Global  NMI = 0.3247 ARI = 0.2084 F = 0.3049 ACC = 0.3812
count 36
Round:  110 Train Loss: -1.941
count 36
Round:  111 Train Loss: -1.941
count 36
Round:  112 Train Loss: -1.939
count 36
Round:  113 Train Loss: -1.943
count 36
Round:  114 Train Loss: -1.941
centeral clustering
Global  NMI = 0.2909 ARI = 0.1647 F = 0.2630 ACC = 0.3231
count 36
Round:  115 Train Loss: -1.943
count 36
Round:  116 Train Loss: -1.944
count 36
Round:  117 Train Loss: -1.940
count 36
Round:  118 Train Loss: -1.942
count 36
Round:  119 Train Loss: -1.937
centeral clustering
Global  NMI = 0.2984 ARI = 0.1711 F = 0.2616 ACC = 0.3438
Global  NMI = 0.3197 ARI = 0.1942 F = 0.3007 ACC = 0.3411
count 36
Round:  120 Train Loss: -1.935
count 36
Round:  121 Train Loss: -1.933
count 36
Round:  122 Train Loss: -1.935
count 36
Round:  123 Train Loss: -1.934
count 36
Round:  124 Train Loss: -1.933
centeral clustering
Global  NMI = 0.2846 ARI = 0.1672 F = 0.2613 ACC = 0.3462
count 36
Round:  125 Train Loss: -1.935
